# Browser Vigilant v2.0 â€” Full Implementation Plan

---

## ğŸ”‘ Core Principles

1. **Zero blacklist at runtime** â€” the ML model scores any URL from math features alone
2. **Zero telemetry** â€” no URL, no feature, no verdict ever leaves the device
3. **100% on-device** â€” ONNX inference runs in the browser service worker, ~3ms
4. **Threat Vault** (not "ledger") â€” Merkle-tree of SHA-256 domain hashes, tamper-evident

---

## ğŸ—ï¸ 5-Layer Security Pipeline

```
Navigation fires â†’ webNavigation.onBeforeNavigate (background.js)
                                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LAYER 1 â€” Threat Vault Hash Cache  <0.1ms  â”‚
         â”‚  Merkle-tree of SHA-256(hostname) hashes     â”‚
         â”‚  of every domain this session blocked        â”‚
         â”‚  â”œâ”€ MATCH â†’ instant block, zero ML cost      â”‚
         â”‚  â””â”€ NO MATCH â†’ Layer 2                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LAYER 2 â€” Heuristic Pre-filter  <2ms       â”‚
         â”‚  12 deterministic rules:                     â”‚
         â”‚  Punycode, IP-in-URL, brand Levenshtein â‰¤2, â”‚
         â”‚  suspicious TLD, @ count, subdomain depth,  â”‚
         â”‚  HTTP+login keywords, UPI VPA regex,         â”‚
         â”‚  executable extension, percent-encoding ratioâ”‚
         â”‚  â”œâ”€ score â‰¥ 0.50 â†’ THREAT, block + vault    â”‚
         â”‚  â”œâ”€ score â‰¥ 0.30 â†’ WARNING, notify          â”‚
         â”‚  â””â”€ score < 0.30 â†’ Layer 3                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LAYER 3 â€” Bayesian URL Scorer  <1ms        â”‚
         â”‚  NaÃ¯ve Bayes on 8 URL token n-grams (2,3)   â”‚
         â”‚  pre-computed character frequency tables     â”‚
         â”‚  Fast probabilistic pre-filter before ONNX  â”‚
         â”‚  â”œâ”€ P(phish) > 0.85 â†’ THREAT, block + vault â”‚
         â”‚  â”œâ”€ P(phish) > 0.55 â†’ go to Layer 4 anyway  â”‚
         â”‚  â””â”€ P(phish) < 0.15 â†’ SAFE, skip Layer 4   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ (ambiguous 0.15â€“0.85)
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LAYER 4 â€” ONNX ML Ensemble  <5ms           â”‚
         â”‚  Random Forest (300 trees) +                 â”‚
         â”‚  XGBoost (200 rounds) soft-vote              â”‚
         â”‚  Trained on 235k+ real URLs (5 datasets)    â”‚
         â”‚  Input: 56 math features from URL string     â”‚
         â”‚  Output: P(phishing) âˆˆ [0.0, 1.0]           â”‚
         â”‚  â”œâ”€ P â‰¥ 0.50 â†’ THREAT, block + vault        â”‚
         â”‚  â”œâ”€ P â‰¥ 0.30 â†’ WARNING, notify              â”‚
         â”‚  â””â”€ P < 0.30 â†’ SAFE                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ (page loads)
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LAYER 5 â€” DOM Behavioral Engine  async     â”‚
         â”‚  Runs after DOMContentLoaded via content.js  â”‚
         â”‚  MutationObserver watches live DOM changes   â”‚
         â”‚  Detects: credential-harvesting forms,       â”‚
         â”‚  hidden iframes, clipboard hijacking,        â”‚
         â”‚  eval(atob()) obfuscation, fake overlays,    â”‚
         â”‚  UPI QR codes, form action domain mismatch   â”‚
         â”‚  â”œâ”€ CRITICAL signal â†’ inject alert banner    â”‚
         â”‚  â””â”€ Sends final verdict to background.js     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Training Data Sources (Offline â€” no runtime downloads)

| Dataset | Size | URLs | Source |
|---------|------|------|--------|
| **PhiUSIIL** (UCI, 2024) | 235,795 URLs | 134,850 legit + 100,945 phishing | `archive.ics.uci.edu/dataset/967` |
| **ISCX-URL-2016** (CIC/UNB) | 36,707 URLs | Benign, phishing, malware, spam, defacement | `www.unb.ca/cic/datasets/url-2016.html` |
| **PhishTank live CSV** | ~50k URLs | Active phishing, community-verified | `data.phishtank.com/data/online-valid.csv` |
| **Tranco top-1M** | top 15k sampled | High-confidence legitimate sites | `tranco-list.eu/top-1m.csv.zip` |
| **Mendeley 2024** | 450,176 URLs | 104k phishing + 345k legit | PhishTank + Majestic Million |

**Total training corpus: ~250,000â€“450,000 URL samples** (after deduplication and balance sampling)

**train.py downloads all 5 datasets at training time** (one-time offline script, not at runtime).

---

## ğŸ§  ML Techniques & Math

### Feature Engineering â€” 56 URL Features

> All features computed from URL string alone. Zero network calls. Zero page content access.

**Group A â€” Lexical Structure (16 features)**
| # | Feature | Math |
|---|---------|------|
| 0 | URL length | [len(url)](file:///d:/Browser-Vigilant/background.js#343-358) |
| 1â€“3 | Domain / Path / Query length | [len(part)](file:///d:/Browser-Vigilant/background.js#343-358) |
| 4â€“8 | Dot, hyphen, underscore, slash, @ counts | `str.count(char)` |
| 9 | Digit count | `Î£ isdigit(c)` |
| 10 | Digit ratio | `digits / len(url)` |
| 11 | HTTPS flag | `1 if scheme=="https" else 0` |
| 12 | IP-in-URL | regex `\d{1,3}(\.\d{1,3}){3}` |
| 13 | Punycode | `"xn--" in host` |
| 14 | Subdomain depth | [len(labels) - 2](file:///d:/Browser-Vigilant/background.js#343-358) |
| 15 | Port anomaly | `port not in {80,443,8080}` |

**Group B â€” Information Theory (3 features)**
| # | Feature | Math |
|---|---------|------|
| 15 | URL Shannon entropy | `H = -Î£ p(c) Â· logâ‚‚(p(c))` |
| 16 | Domain Shannon entropy | same, over domain chars |
| 17 | Path Shannon entropy | same, over path chars |

These three detect random-looking strings typical of auto-generated phishing domains.

**Group C â€” Brand Similarity (3 features)**
| # | Feature | Math |
|---|---------|------|
| 18 | Min Levenshtein distance to 50 brands | Wagner-Fischer `O(mÃ—n)` |
| 19 | Brand-spoof flag | `1 if 0 < dist â‰¤ 2` |
| 20 | Brand in subdomain only | `brand in subdomain AND brand not in reg_domain` |

**Group D â€” Keyword Signals (6 features)**
Binary flags: login keywords, trust-word misuse, payment keywords, free/prize keywords, fraud action words, UPI VPA regex match.

**Group E â€” URL Obfuscation & Encoding (5 features)**
Percent-encoding ratio, double extension path (`pdf.exe`), base64-in-query detection, path traversal (`../`), fragment presence.

**Group F â€” Domain Quality (8 features)**
Suspicious TLD lookup, TLD length, vowel ratio in domain, max consecutive consonants, URL char compression ratio, short-URL service flag, numeric-only domain flag, query param count.

**Group G â€” UPI/Payment Specific (3 features)**
UPI VPA pattern match, suspicious VPA prefix (refund/tax/kyc), fake UPI handle Levenshtein score.

---

### Model Architecture

```
56 float features
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  â”‚         â”‚
  RF        XGBoost
300 trees   200 rounds
depth=8     depth=6
sqrt feats  eta=0.05
balanced    subsample=0.8
  â”‚         â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚ Soft Vote: avg(P_RF, P_XGBoost)
       â”‚
  Platt Scaling (CalibratedClassifierCV)
       â”‚ calibrates P â†’ true probability
       â–¼
  P(phishing) âˆˆ [0.0, 1.0]
```

**Why XGBoost over GBM:** XGBoost achieves 98.7% accuracy on URL datasets vs GBM's ~96%. It uses second-order gradient approximation and regularization (L1+L2) to prevent overfitting on the larger 250k dataset.

**Why Platt Scaling:** Raw RF/XGBoost output probabilities are poorly calibrated (overconfident). Platt Scaling fits a logistic regression on CV predictions: `P_cal = 1 / (1 + exp(AÂ·f + B))` where A, B are fitted on held-out fold predictions.

**Why SMOTE for balance:** If dataset has 70% legit / 30% phishing, SMOTE (Synthetic Minority Oversampling TEchnique) generates synthetic phishing samples via k-NN interpolation in feature space rather than simple duplication.

### Cross-Validation & Evaluation
- **10-fold stratified CV** â†’ each fold has same phishing ratio
- Metrics reported: Accuracy, Precision, Recall, F1, **ROC-AUC** (main metric)
- Target: ROC-AUC â‰¥ 0.97, F1 â‰¥ 0.95

### Explainability (Shapley Values)
For popup UI "Threat DNA" display:
```python
import shap
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)
# top-5 contributing features per URL shown in popup
```
This shows the user exactly WHY a site was flagged (e.g., "Brand Spoof +0.34, Suspicious TLD +0.28").

---

## ğŸ”’ Threat Vault (Replaces "Ledger")

**Not a "ledger". Not a "log". It's a Merkle-tree Threat Vault.**

### What is it
A Merkle tree where each leaf node is `SHA-256(hostname)` of a confirmed-blocked domain. The root hash proves tamper-evidence for the entire vault.

```
            Root Hash
           /         \
      H(L1|L2)     H(L3|L4)
       /   \         /   \
    H(d1) H(d2)  H(d3) H(d4)
     â”‚     â”‚       â”‚     â”‚
  SHA256 SHA256 SHA256 SHA256
  (host1)(host2)(host3)(host4)
```

**Why Merkle over chain**: A Merkle tree allows O(log n) inclusion proofs â€” you can verify a single domain is in the vault without reading all entries. Blockchain chains force O(n) traversal. Merkle is also standard in certificate transparency (Google CT logs) and Git's object store.

### Privacy: Why SHA-256(hostname) is safe
- The raw URL is **never stored** â€” only the hash
- SHA-256 is a one-way function: `SHA-256("evil-phish.xyz") â†’ "a4f3b..."` â€” cannot reverse
- No browsing history is preserved â€” a hash tells you nothing about the user's session
- Even if the vault is stolen, an attacker only gets a list of domain hashes â€” no user data

### In-Memory Fast Path
On startup: vault hashes loaded into a JS [Set](file:///d:/Browser-Vigilant/background.js#137-141) â†’ O(1) lookup per navigation.
On new block: hash added to Set immediately + Merkle root recomputed + persisted to `chrome.storage.local`.

---

## ğŸ” Privacy Architecture

> [!IMPORTANT]
> Zero-capture design: No URL, hostname, or feature vector ever leaves the device.

| Concern | Solution |
|---------|---------|
| URLs stored in history | Only SHA-256 digest of domain stored in vault â€” raw URL stored in session-only scan history, clearable by user |
| ML model sent to server | ONNX file is bundled with extension at install time â€” no external inference |
| Training data contains user browsing | Training happens offline on developer machine with public datasets only |
| Vault stolen from storage | Contains only one-way SHA-256 hashes â€” mathematically irreversible |
| Feature vectors leak URL info | Features are math transforms (entropy, lengths, ratios) â€” non-invertible |
| Chrome storage readable | `chrome.storage.local` is sandboxed to extension â€” no website can read it |
| History tab shows URLs | Stored encrypted with `chrome.storage.local` â€” user can clear at any time |
| Notifications show URL | Truncated to hostname only, not full path |

---

## ğŸ“ Files to Change

### [MODIFY] [model/train.py](file:///d:/Browser-Vigilant/model/train.py)
- Download PhiUSIIL + PhishTank + Tranco at training time
- Extract 56 features via [features.py](file:///d:/Browser-Vigilant/model/features.py)
- Train RF + XGBoost with SMOTE + Platt Scaling
- 10-fold CV metrics
- Export `model.onnx`

### [MODIFY] [model/features.py](file:///d:/Browser-Vigilant/model/features.py)
- Expand from 48 to 56 features (add 8 from Group F/G)
- Keep identical feature order between Python and Rust WASM

### [MODIFY] [model/requirements.txt](file:///d:/Browser-Vigilant/model/requirements.txt)
- Add: `xgboost`, `imbalanced-learn`, `shap`, `requests`, `tqdm`
- Bump: `scikit-learn >= 1.4`, `onnxruntime >= 1.18`

### [MODIFY] [background.js](file:///d:/Browser-Vigilant/background.js)
- Add `blockedDomainHashes` in-memory Set
- Add Merkle root computation and verification
- Add `domainHash` field to vault blocks
- Add `SCAN_URL` message handler for popup scanner
- Add Bayesian pre-scorer (Layer 3) using pre-trained character frequency tables
- Add Layer 1 vault lookup BEFORE heuristics in `webNavigation.onBeforeNavigate`

### [MODIFY] [popup/src/components/Shield.svelte](file:///d:/Browser-Vigilant/popup/src/components/Shield.svelte)
- Remove `quickScan()`, `SCAN_BRANDS`, `SCAN_SUSP_TLDS`, `scanLev()` â€” all duplicated logic
- Replace with `chrome.runtime.sendMessage({ type: "SCAN_URL", url })` call
- Display Shapley feature importance bars ("Threat DNA")

### [MODIFY] [popup/src/App.svelte](file:///d:/Browser-Vigilant/popup/src/App.svelte)
- Fix popup width to 380px (Chrome extension constraint)

### [MODIFY] [popup/src/components/ThreatMap.svelte](file:///d:/Browser-Vigilant/popup/src/components/ThreatMap.svelte)
- Rename references from "ledger" to "Threat Vault"
- Show Merkle root hash for vault integrity proof

---

## âœ… Verification Plan

### 1. Train model (offline, once)
```bash
cd model && pip install -r requirements.txt && python train.py
# Expected: ROC-AUC â‰¥ 0.97, model.onnx created
```
### 2. Smoke test ONNX
```bash
python -c "
import onnxruntime as rt, numpy as np
from features import extract_features
urls = [('http://paypal-secure.verify.xyz/signin', '>0.7'),
        ('https://www.github.com', '<0.2')]
sess = rt.InferenceSession('model.onnx')
for url, expect in urls:
    f = np.array([extract_features(url)], dtype=np.float32)
    p = sess.run(None, {'input': f})[1][0][1]
    print(f'{url[:45]} â†’ {p:.3f} (expect {expect})')
"
```
### 3. Build popup
```bash
cd popup && npm run build  # generates dist-popup/
```
### 4. Load extension + manual navigation tests
- `http://paypal-secure.account-verify.xyz` â†’ blocked
- `https://www.google.com` â†’ safe
- Second visit to blocked domain â†’ instant vault block (<0.1ms, no ML)
